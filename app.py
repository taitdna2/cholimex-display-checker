# Streamlit web app cho "Cholimex Display Checker"
from __future__ import annotations
import io, os, re, json
from typing import Dict, List, Tuple, Optional
from datetime import datetime

import streamlit as st
import pandas as pd

# =========================
# DEFAULT CONFIG (fallback)
# =========================
DEFAULT_CONFIG = {
    "muc_toi_thieu": {
        "NMCD": 150000, "DHLM": 100000, "KOS_XXTG": 300000, "LTLKC": 80000,
        "GVIG": 300000, "GVIG_BMTR": 300000, "KOS_XXTG_BS": 200000,
        "CAKOS": 50000, "XBM_MN": 36000, "XBM_MB": 36000
    },
    "program_names": {
        "NMCD": "Tr∆∞ng b√†y N∆∞·ªõc m·∫Øm Cholimex 30, 35, 40 ƒë·ªô ƒë·∫°m 500ml + 750ml",
        "DHLM": "Tr∆∞ng b√†y D·∫ßu h√†o 820g, N∆∞·ªõc t∆∞∆°ng L√™n men 700ml",
        "LTLKC": "Tr∆∞ng b√†y X·ªët L·∫©u th√°i 280g & X·ªët L·∫©u kim chi 280g",
        "KOS_XXTG": "Tr∆∞ng b√†y c√° KOS v√† X√∫c x√≠ch - Mi·ªÅn Nam",
        "KOS_XXTG_BS": "Tr∆∞ng b√†y c√° KOS v√† X√∫c x√≠ch - Mi·ªÅn B·∫Øc & B·∫Øc Mi·ªÅn Trung",
        "XBM_MN": "Tr∆∞ng b√†y Xe B√°nh M√¨ - Mi·ªÅn Nam",
        "XBM_MB": "Tr∆∞ng b√†y Xe B√°nh M√¨ - Mi·ªÅn B·∫Øc",
        "CAKOS": "Tr∆∞ng b√†y c√° KOS",
        "GVIG": "Tr∆∞ng b√†y Gia v·ªã g√≥i - Mi·ªÅn B·∫Øc",
        "GVIG_BMTR": "Tr∆∞ng b√†y Gia v·ªã g√≥i - B·∫Øc Mi·ªÅn Trung"
    },
    "region_map": {
        "HCME": ["HCM", "MD"],
        "MTRUNG": ["MTR", "MB_MT3"],
        "MTAY": ["MTA"],
        "MBAC": ["MB"],
        "TOAN_QUOC": "ALL"
    },
    # map ri√™ng cho Xe B√°nh M√¨
    "xbm_map": {"M70": "XBM_MN", "M110": "XBM_MN", "M80": "XBM_MB", "M120": "XBM_MB"}
}

# ============ CONFIG LOADER ============
def _load_json_text(text: str) -> Optional[dict]:
    try:
        return json.loads(text)
    except Exception:
        return None

@st.cache_data(show_spinner=False)
def load_config(overrides: dict | None = None) -> Dict:
    cfg = DEFAULT_CONFIG.copy()
    if overrides:
        for k in ["muc_toi_thieu","program_names","region_map","xbm_map"]:
            if k in overrides and isinstance(overrides[k], dict):
                cfg[k] = overrides[k]
    return cfg

# =============== UTILITIES ===============
def parse_stage_value(giai_doan: str) -> Tuple[int,int,str]:
    """
    Chuy·ªÉn 'Th√°ng 11/2025' ‚Üí (2025, 11, 'Th√°ng 11/2025'), d√πng ƒë·ªÉ sort.
    N·∫øu kh√¥ng b·∫Øt ƒë∆∞·ª£c, tr·∫£ (0,0,raw).
    """
    if not isinstance(giai_doan, str): return (0,0,str(giai_doan))
    m = re.search(r"(\d{1,2}).*?(\d{4})", giai_doan)
    if not m: return (0,0,giai_doan)
    mm, yy = int(m.group(1)), int(m.group(2))
    return (yy, mm, giai_doan)

def fmt_money(x):
    try:
        return f"{int(round(float(x))):,}".replace(",", ".")
    except Exception:
        return x

# =============== CORE ===============
def xu_ly_file(file: bytes, muc_toi_thieu: Dict[str, float], xbm_map: Dict[str,str]):
    df = pd.read_excel(io.BytesIO(file), header=1, dtype={"M√£ kh√°ch h√†ng": str, "M√£ NPP": str})
    cols_in = ["M·ª©c ƒëƒÉng k√Ω","Mi·ªÅn","V√πng","M√£ NPP","T√™n NPP","Giai ƒëo·∫°n","M√£ NVBH","T√™n NVBH",
               "M√£ kh√°ch h√†ng","T√™n kh√°ch h√†ng","Th·ª© b√°n h√†ng","Tuy·∫øn","S·ªë su·∫•t ƒëƒÉng k√≠","Doanh s·ªë t√≠ch l≈©y hi·ªán t·∫°i"]
    df = df[[c for c in cols_in if c in df.columns]].copy()

    df.rename(columns={
        "M·ª©c ƒëƒÉng k√Ω":"MucDK","Mi·ªÅn":"Mien","V√πng":"Vung","M√£ NPP":"MaNPP","T√™n NPP":"TenNPP",
        "Giai ƒëo·∫°n":"GiaiDoan","M√£ NVBH":"MaNVBH","T√™n NVBH":"TenNVBH",
        "M√£ kh√°ch h√†ng":"MaKH","T√™n kh√°ch h√†ng":"TenKH",
        "Th·ª© b√°n h√†ng":"ThuBanHang","Tuy·∫øn":"Tuyen",
        "S·ªë su·∫•t ƒëƒÉng k√≠":"SoSuat","Doanh s·ªë t√≠ch l≈©y hi·ªán t·∫°i":"DoanhSo"
    }, inplace=True)

    if "Tuyen" not in df.columns: df["Tuyen"] = None
    if "ThuBanHang" not in df.columns: df["ThuBanHang"] = None

    muc_map = df["MucDK"].astype(str).str.strip().map(xbm_map).fillna(df["MucDK"].astype(str).str.strip())
    base = muc_map.map(muc_toi_thieu).fillna(0).astype(float)
    df["NguongToiThieu"] = base * pd.to_numeric(df["SoSuat"], errors="coerce").fillna(0).astype(float)

    giai_doan = str(df["GiaiDoan"].iloc[0]).strip()
    df[f"SoSuat_{giai_doan}"] = df["SoSuat"]
    df[f"DoanhSo_{giai_doan}"] = df["DoanhSo"]
    df[f"Nguong_{giai_doan}"] = df["NguongToiThieu"]
    return df, giai_doan

def xu_ly_chuong_trinh(file_t1: bytes, file_t2: bytes, muc_toi_thieu, program_names, xbm_map,
                        file_t0: bytes | None = None,
                        filter_ketqua: Optional[set] = None,
                        filter_tuyen_tokens: Optional[List[str]] = None):
    df1, g1 = xu_ly_file(file_t1, muc_toi_thieu, xbm_map)
    df2, g2 = xu_ly_file(file_t2, muc_toi_thieu, xbm_map)

    new_in_T1_keys = set()
    if file_t0:
        df0, g0 = xu_ly_file(file_t0, muc_toi_thieu, xbm_map)
        keys_t0 = set(zip(df0["MaKH"], df0["MucDK"]))
        keys_t1 = set(zip(df1["MaKH"], df1["MucDK"]))
        new_in_T1_keys = keys_t1 - keys_t0
    else:
        df0, g0 = None, None

    df = pd.merge(df1, df2, on=["MaKH","MucDK"], how="outer", suffixes=("_T1","_T2"))
    if df0 is not None:
        df = df.merge(df0[["MaKH", f"SoSuat_{g0}", f"DoanhSo_{g0}"]], on="MaKH", how="left")

    for col in [f"SoSuat_{g1}", f"SoSuat_{g2}", f"DoanhSo_{g1}", f"DoanhSo_{g2}", f"Nguong_{g1}", f"Nguong_{g2}"]:
        if col in df.columns: df[col] = df[col].fillna(0)

    def xet(row):
        ds1, ds2 = row.get(f"DoanhSo_{g1}",0) or 0, row.get(f"DoanhSo_{g2}",0) or 0
        ss1, ss2 = row.get(f"SoSuat_{g1}",0) or 0, row.get(f"SoSuat_{g2}",0) or 0
        n1, n2 = row.get(f"Nguong_{g1}",0) or 0, row.get(f"Nguong_{g2}",0) or 0
        key = (row.get("MaKH"), row.get("MucDK"))
        if ss1 > 0 and ss2 == 0: return "XOA", "Th√°ng tr∆∞·ªõc c√≥ tham gia, th√°ng sau kh√¥ng tham gia"
        if ss1 > 0 and key in new_in_T1_keys: return "ƒê·∫°t", "Kh√°ch m·ªõi th√°ng tr∆∞·ªõc (DS x√©t chu k·ª≥ 11/T0‚Üí10/T1)"
        if ss1 == 0 and ss2 > 0: return "Kh√¥ng x√©t", "Kh√°ch h√†ng m·ªõi th√°ng sau (kh√¥ng x√©t k·∫øt qu·∫£ k·ª≥ n√†y)"
        if ss2 > ss1 > 0: return "ƒê·∫°t", f"N√¢ng su·∫•t {int(ss1)}‚Üí{int(ss2)}"
        if ss2 < ss1:
            if (ds1 >= n1) or (ds2 >= n2): return "ƒê·∫°t", f"Gi·∫£m su·∫•t {int(ss1)}‚Üí{int(ss2)} (ƒë·ªß 1 trong 2)"
            else: return "Kh√¥ng ƒë·∫°t", f"Gi·∫£m su·∫•t {int(ss1)}‚Üí{int(ss2)} (thi·∫øu)"
        if (ds1 >= n1) or (ds2 >= n2): return "ƒê·∫°t",""
        return "Kh√¥ng ƒë·∫°t","Thi·∫øu"

    df[["KetQua","GhiChu"]] = df.apply(lambda r: pd.Series(xet(r)), axis=1)

    df_removed = df[df["KetQua"]=="XOA"].copy()
    df_final  = df[df["KetQua"]!="XOA"].copy()

    # l·ªçc theo k·∫øt qu·∫£
    if filter_ketqua is not None:
        df_final = df_final[df_final["KetQua"].isin(filter_ketqua)]

    # l·ªçc theo 'Th·ª© b√°n h√†ng' (fallback 'Tuy·∫øn') ‚Äî KH√îNG xu·∫•t c·ªôt 'Tuy·∫øn'
    route_col = "ThuBanHang_T2" if "ThuBanHang_T2" in df_final.columns else ("Tuyen_T2" if "Tuyen_T2" in df_final.columns else None)
    if filter_tuyen_tokens and route_col:
        toks = [t.lower() for t in filter_tuyen_tokens if t]
        df_final = df_final[df_final[route_col].astype(str).str.lower().apply(lambda s: any(t in s for t in toks))]

    # ch·ªçn c·ªôt xu·∫•t ra
    cols_out = [
        "MucDK","Mien_T2","Vung_T2","MaNPP_T2","TenNPP_T2","MaNVBH_T2","TenNVBH_T2",
        "MaKH","TenKH_T2","ThuBanHang_T2",
        f"SoSuat_{g1}", f"SoSuat_{g2}",
        f"DoanhSo_{g1}", f"DoanhSo_{g2}",
        f"Nguong_{g2}", "KetQua","GhiChu"
    ]
    if df0 is not None:
        cols_out.insert(10, f"SoSuat_{g0}")
        cols_out.insert(11, f"DoanhSo_{g0}")

    rename = {
        "MucDK":"M·ª©c ƒëƒÉng k√Ω","Mien_T2":"Mi·ªÅn","Vung_T2":"V√πng",
        "MaNPP_T2":"M√£ NPP","TenNPP_T2":"T√™n NPP","MaNVBH_T2":"M√£ NVBH","TenNVBH_T2":"T√™n NVBH",
        "MaKH":"M√£ kh√°ch h√†ng","TenKH_T2":"T√™n kh√°ch h√†ng","ThuBanHang_T2":"Th·ª© b√°n h√†ng",
        f"SoSuat_{g1}":f"S·ªë su·∫•t ƒëƒÉng k√Ω {g1}", f"SoSuat_{g2}":f"S·ªë su·∫•t ƒëƒÉng k√Ω {g2}",
        f"DoanhSo_{g1}":f"Doanh s·ªë t√≠ch l≈©y {g1}", f"DoanhSo_{g2}":f"Doanh s·ªë t√≠ch l≈©y {g2}",
        f"Nguong_{g2}":"Ng∆∞·ª°ng t·ªëi thi·ªÉu","KetQua":"K·∫øt qu·∫£","GhiChu":"Ghi ch√∫"
    }
    if df0 is not None:
        rename[f"SoSuat_{g0}"] = f"S·ªë su·∫•t ƒëƒÉng k√Ω {g0}"
        rename[f"DoanhSo_{g0}"] = f"Doanh s·ªë t√≠ch l≈©y {g0}"

    out = df_final[cols_out].copy().rename(columns=rename)
    removed_out = df_removed[cols_out].copy().rename(columns=rename)
    return out, removed_out

# ======== GROUP FILES B·∫∞NG C·ªòT "GIAI ƒêO·∫†N" + "M·ª®C ƒêƒÇNG K√ù" (KH·ªéI ƒê·ªîI T√äN FILE) ========
def derive_ct_key(df: pd.DataFrame, xbm_map: Dict[str,str]) -> str:
    # T·ª± x√°c ƒë·ªãnh CT t·ª´ "M·ª©c ƒëƒÉng k√Ω" (ƒë·∫∑c bi·ªát XBM)
    mucs = df["M·ª©c ƒëƒÉng k√Ω"] if "M·ª©c ƒëƒÉng k√Ω" in df.columns else df.get("MucDK")
    if mucs is None or mucs.empty:
        return "UNKNOWN"
    first = str(mucs.iloc[0]).strip()
    mapped = xbm_map.get(first, first)
    # n·∫øu v·∫´n l√† m√£ XBM_MN/MB hay t√™n CT kh√°c th√¨ d√πng lu√¥n
    return mapped

def group_files_by_content(uploaded_files, xbm_map: Dict[str,str]):
    """
    Tr·∫£ v·ªÅ dict: { CT: {stage_key: file_bytes} }
    stage_key ƒë∆∞·ª£c s·∫Øp theo th·ªùi gian d·ª±a v√†o c·ªôt 'Giai ƒëo·∫°n'
    """
    groups: Dict[str, Dict[str, bytes]] = {}
    for uf in uploaded_files:
        df_preview = pd.read_excel(uf, header=1, nrows=5)
        ct = derive_ct_key(df_preview, xbm_map)
        # l·∫•y giai ƒëo·∫°n
        g = str(df_preview["Giai ƒëo·∫°n"].iloc[0]).strip() if "Giai ƒëo·∫°n" in df_preview.columns else "Th√°ng ?/?"
        yy, mm, label = parse_stage_value(g)
        key = f"{yy:04d}-{mm:02d}|{label}"  # sort ƒë∆∞·ª£c
        # c·∫ßn bytes (v√¨ streamlit tr·∫£ file-like)
        uf.seek(0)
        data = uf.read()
        groups.setdefault(ct, {})[key] = data
    return groups

# =============== UI ===============
st.set_page_config(page_title="Cholimex Display Checker", page_icon="üìä", layout="wide")
st.title("Cholimex Display Checker (Web)")

with st.expander("‚öôÔ∏è Tu·ª≥ ch·ªçn c·∫•u h√¨nh (kh√¥ng b·∫Øt bu·ªôc)"):
    cfg_text = st.text_area("D√°n JSON override cho config (muc_toi_thieu / program_names / region_map / xbm_map):", height=120, placeholder='{"xbm_map":{"M70":"XBM_MN"}}')
    overrides = _load_json_text(cfg_text) if cfg_text.strip() else None

cfg = load_config(overrides)
muc_toi_thieu = cfg["muc_toi_thieu"]
program_names = cfg["program_names"]
region_map = cfg["region_map"]
xbm_map = cfg["xbm_map"]

uploaded = st.file_uploader("T·∫£i nhi·ªÅu file Excel (.xls/.xlsx) ‚Äî m·ªói CT √≠t nh·∫•t 2 th√°ng", type=["xls","xlsx"], accept_multiple_files=True)

colA, colB, colC = st.columns([1.2,1.2,1.6])

with colA:
    regions = st.multiselect("‚ë° Ch·ªçn mi·ªÅn", list(region_map.keys()), default=[])

with colB:
    mode = st.selectbox("‚ë¢ Ch·∫ø ƒë·ªô xu·∫•t", ["MKT","GSBH"], index=0)

with colC:
    st.write("‚ë£ B·ªô l·ªçc K·∫øt qu·∫£")
    kq_all   = st.checkbox("T·∫•t c·∫£", value=False)
    kq_dat   = st.checkbox("ƒê·∫°t", value=False)
    kq_kdat  = st.checkbox("Kh√¥ng ƒë·∫°t", value=False)
    kq_kxet  = st.checkbox("Kh√¥ng x√©t", value=False)

do_run = st.button("‚ñ∂Ô∏é X·ª≠ l√Ω & Xu·∫•t Excel", use_container_width=True)

if do_run:
    if not uploaded:
        st.warning("Vui l√≤ng ch·ªçn file Excel tr∆∞·ªõc.")
    elif not regions:
        st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t 1 mi·ªÅn.")
    else:
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            groups = group_files_by_content(uploaded, xbm_map)

            # x√°c ƒë·ªãnh filter k·∫øt qu·∫£
            if kq_all or (not any([kq_dat, kq_kdat, kq_kxet])):
                selected_kq = None
            else:
                sel = set()
                if kq_dat:  sel.add("ƒê·∫°t")
                if kq_kdat: sel.add("Kh√¥ng ƒë·∫°t")
                if kq_kxet: sel.add("Kh√¥ng x√©t")
                selected_kq = sel if sel else None

            # xu·∫•t 1 file/t·ª´ng mi·ªÅn
            all_outputs = {}

            for region in regions:
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine="openpyxl") as writer_kq:
                    writer_xoa = None
                    if mode != "GSBH":
                        xoa_buf = io.BytesIO()
                        writer_xoa = pd.ExcelWriter(xoa_buf, engine="openpyxl")

                    bao_cao_data, bao_cao_huy = [], []

                    ct_idx = 0
                    for ct, files_dict in groups.items():
                        # s·∫Øp theo th·ªùi gian
                        ordered = sorted(files_dict.items(), key=lambda x: x[0])
                        if len(ordered) < 2:
                            continue
                        # l·∫•y T2 l√† cu·ªëi, T1 l√† k·∫ø cu·ªëi, T0 n·∫øu c√≥ l√† ƒë·∫ßu
                        f_t2 = ordered[-1][1]
                        f_t1 = ordered[-2][1]
                        f_t0 = ordered[0][1] if len(ordered) >= 3 else None

                        try:
                            df_out, df_removed_out = xu_ly_chuong_trinh(
                                file_t1=f_t1, file_t2=f_t2,
                                muc_toi_thieu=muc_toi_thieu,
                                program_names=program_names,
                                xbm_map=xbm_map,
                                file_t0=f_t0,
                                filter_ketqua=selected_kq,
                                filter_tuyen_tokens=None,
                            )
                        except Exception as e:
                            st.error(f"L·ªói x·ª≠ l√Ω CT {ct}: {e}")
                            continue

                        # l·ªçc mi·ªÅn
                        if region_map.get(region) != "ALL":
                            df_out = df_out[df_out["Mi·ªÅn"].isin(region_map[region])]
                            df_removed_out = df_removed_out[df_removed_out["Mi·ªÅn"].isin(region_map[region])]

                        # GSBH: ghi ch√∫ ch·ªâ c√≤n "Thi·∫øu: xxx"
                        if mode == "GSBH":
                            doanh_so_cols = sorted([c for c in df_out.columns if c.startswith("Doanh s·ªë t√≠ch l≈©y ")])
                            if doanh_so_cols and "Ng∆∞·ª°ng t·ªëi thi·ªÉu" in df_out.columns:
                                col_ds_t2 = doanh_so_cols[-1]
                                mask_nd = df_out["K·∫øt qu·∫£"].eq("Kh√¥ng ƒë·∫°t")
                                remain = (df_out.loc[mask_nd,"Ng∆∞·ª°ng t·ªëi thi·ªÉu"].astype(float)
                                          - df_out.loc[mask_nd,col_ds_t2].astype(float)).clip(lower=0)
                                df_out.loc[mask_nd,"Ghi ch√∫"] = remain.map(lambda v: f"Thi·∫øu: {fmt_money(v)}")

                            keep = ["M·ª©c ƒëƒÉng k√Ω","T√™n NPP","M√£ NVBH","T√™n NVBH","M√£ kh√°ch h√†ng","T√™n kh√°ch h√†ng","Th·ª© b√°n h√†ng"]
                            so_suat_cols = sorted([c for c in df_out.columns if c.startswith("S·ªë su·∫•t ƒëƒÉng k√Ω ")])
                            ds_cols = sorted([c for c in df_out.columns if c.startswith("Doanh s·ªë t√≠ch l≈©y ")])
                            if len(so_suat_cols)>=2: keep += [so_suat_cols[-2],so_suat_cols[-1]]
                            elif len(so_suat_cols)==1: keep += [so_suat_cols[-1]]
                            if len(ds_cols)>=2: keep += [ds_cols[-2],ds_cols[-1]]
                            elif len(ds_cols)==1: keep += [ds_cols[-1]]
                            keep += ["Ng∆∞·ª°ng t·ªëi thi·ªÉu","K·∫øt qu·∫£","Ghi ch√∫"]
                            keep = [c for c in keep if c in df_out.columns]
                            df_out = df_out[keep]

                        # ghi sheet
                        df_out.to_excel(writer_kq, sheet_name=ct, index=False)

                        if mode != "GSBH" and writer_xoa is not None:
                            df_removed_out.to_excel(writer_xoa, sheet_name=ct, index=False)

                        # t·ªïng h·ª£p
                        try:
                            tong = df_out.filter(like="S·ªë su·∫•t ƒëƒÉng k√Ω").iloc[:, -1].sum()
                            ko_dat = df_out.loc[df_out["K·∫øt qu·∫£"]=="Kh√¥ng ƒë·∫°t",:].filter(like="S·ªë su·∫•t ƒëƒÉng k√Ω").iloc[:, -1].sum()
                            tile = f"{(ko_dat/tong):.1%}" if tong>0 else "0%"
                            ct_idx += 1
                            bao_cao_data.append([ct_idx, program_names.get(ct, ct), muc_toi_thieu.get(ct,0), int(tong), int(ko_dat), tile])
                            if mode != "GSBH":
                                bao_cao_huy.append([ct_idx, program_names.get(ct, ct), int(ko_dat)])
                        except Exception:
                            pass

                    # sheet t·ªïng h·ª£p (ƒë∆°n gi·∫£n)
                    if bao_cao_data:
                        df_tong = pd.DataFrame(bao_cao_data, columns=[
                            "STT","T√™n ch∆∞∆°ng tr√¨nh","DOANH S·ªê T·ªêI THI·ªÇU PH√ÅT SINH/ SU·∫§T/ TH√ÅNG (VND)",
                            "T·ªîNG S·ªê SU·∫§T TR∆ØNG B√ÄY","S·ªê SU·∫§T KH√îNG ƒê·∫†T","T·ªà L·ªÜ"
                        ])
                        df_tong.to_excel(writer_kq, sheet_name="BaoCao_TongHop", index=False)

                    if (mode!="GSBH") and bao_cao_huy:
                        df_huy = pd.DataFrame(bao_cao_huy, columns=["STT","T√™n ch∆∞∆°ng tr√¨nh","T·ªîNG S·ªê SU·∫§T H·ª¶Y TR∆ØNG B√ÄY TR√äN HT DMS"])
                        df_huy.to_excel(writer_kq, sheet_name="BaoCao_Huy", index=False)

                # l∆∞u file
                fname = f"TongHop_{region}{'_GSBH' if mode=='GSBH' else ''}.xlsx"
                all_outputs[fname] = output.getvalue()

                if mode != "GSBH" and writer_xoa is not None:
                    fname_x = f"TongHop_Xoa_{region}.xlsx"
                    all_outputs[fname_x] = xoa_buf.getvalue()

        # n√∫t t·∫£i v·ªÅ
        for fn, data in all_outputs.items():
            st.download_button("‚¨áÔ∏è T·∫£i "+fn, data=data, file_name=fn, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        st.success("Xong!")
